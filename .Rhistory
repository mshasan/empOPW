rej
prob_rank_givenEffect_emp <- function(pvalue, filter, group = 5L, h_breaks = 71L,
df = 3, effectType = c("continuous", "binary"))
{
Data = tibble(pvalue, filter)
data_omit_na <- Data[which(!is.na(Data$pvalue)),]
OD <- data_omit_na[order(data_omit_na$filter, decreasing = TRUE), ]
OD_pvalue <- OD$pvalue
grpSize <- ceiling(length(OD_pvalue)/group)
# function to compute ranks probbaility per group--------------
fun_prob <- function(grp)
{
pval_perGrp <- OD_pvalue[(grp*grpSize - grpSize + 1):(grp*grpSize)]
if(effectType == "continuous"){
hist_dens <- hist(pval_perGrp, freq = FALSE,
breaks = seq(0, 1, length = h_breaks))$density
probAll = hist_dens/sum(hist_dens)
prob = probAll[1]
} else {
prob <- 1 - propTrueNull(p = pval_perGrp, method = "lfdr")
}
return(prob)
}
probVec <- sapply(1:group, fun_prob)
# smooting and nomalizing the ranks probability-------------
probVec_smooth <- smooth.spline(x = 1:group, y = probVec, df = df)$y
# if(any(probVec_smooth < 0)){
#     neg_val <- probVec_smooth[probVec_smooth < 0]
#     probVec_smooth <- probVec_smooth - neg_val
# }
probVec_smooth_norm <- probVec_smooth/sum(probVec_smooth, na.rm = TRUE)
return(probVec_smooth_norm)
}
alphaVec <- seq(.05, .1, length = 5)
rej <- NULL
for(alpha in alphaVec){
bot_res <- empOPW(pvalue = pvals, filter = filters, alpha = alpha, tail = 2,
max.group = 15, effectType = "continuous", method = "BH")
rej <- c(rej, bot_res$rejections)
}
rej
empOPW <- function(pvalue, filter, weight = NULL, ranksProb = NULL, mean_testEffect = NULL,
alpha = .05, tail = 1L, delInterval = .0001, max.group = 5L, h_breaks = 71L,
effectType = c("continuous", "binary"), method = c("BH", "BON"), ... )
{
# formulate a data set-------------
Data = tibble(pvalue, filter)
data_omit_na <- Data[which(!is.na(Data$pvalue)),]
OD <- data_omit_na[order(data_omit_na$filter, decreasing = TRUE), ]
OD_pvalue <- OD$pvalue
# compute the number of tests------------
m = length(OD_pvalue)
nullProp = qvalue(p = OD_pvalue, pi0.method = "bootstrap")$pi0
m0 = ceiling(nullProp*m)
m1 = m - m0
#check whether weight is provided------------
if(!is.null(weight)){
wgt <- weight
} else {
# estimate the mean test effect size-------------
if(!is.null(mean_testEffect)){
mean_testEffect <- mean_testEffect
} else {
# compute test statistics from the pvalues---------
test <- qnorm(pvalue/tail, lower.tail = FALSE)
test[which(!is.finite(test))] <- NA
# estimate the true alterantive test effect sizes----------------
if(m1 == 0){
test_effect_vec <- 0
} else {
test_effect_vec <-  sort(test, decreasing = TRUE)[1:m1]
}
# compute mean test effect----------
if(effectType == "continuous"){
mean_testEffect <- mean(test_effect_vec, na.rm = TRUE)
} else {
mean_testEffect <- median(test_effect_vec, na.rm = TRUE)
}
}
# find the optimal number of groups and degrees of freedom----------
grp_seq <- seq(5, max.group, 5)
op_grp_df <- sapply(grp_seq, optimal_group_df, pvalue = OD$pvalue,
filter = OD$filter, h_breaks = h_breaks, m = m, m1 = m1,
alpha = alpha, mean_testEffect = mean_testEffect,
effectType = effectType, method = method)
grp <- op_grp_df[1, which.max(op_grp_df[3,])]
df <- op_grp_df[2, which.max(op_grp_df[3,])]
message("computing ranks probabilities")
# compute the ranks probability of the tests given the mean effect
ranksProb <- prob_rank_givenEffect_emp(pvalue = pvalue, filter = filter,
group = grp, h_breaks = h_breaks, df = df,
effectType = effectType)
message("finished computing the ranks probabilities")
message("computing weights")
if(effectType == "continuous"){
wgt = weight_continuous(alpha = alpha, et = mean_testEffect,
m = grp, ranksProb = ranksProb)
} else {
wgt = weight_binary(alpha = alpha, et = mean_testEffect, m = grp,
m1 = m1/m*grp, ranksProb = ranksProb)
}
message("finished computing the weights")
}
grpSize <- ceiling(m/grp)
wgt_all = rep(wgt, each = grpSize)[1:m]
message("comparing pvalues with thresholds")
if(method == "BH"){
padj <- p.adjust(OD_pvalue/wgt_all, method = "BH")
rejections_list = OD[which((padj <= alpha) == TRUE), ]
} else {
rejections_list = OD[which((OD_pvalue <= alpha*wgt_all/m) == TRUE), ]
}
# outputs--------------
n_rejections = dim(rejections_list)[1]
return(list(totalTests = length(pvalue), nullProp = nullProp,
ranksProb = ranksProb, weight = wgt_all,
rejections = n_rejections, rejections_list = rejections_list))
}
alphaVec <- seq(.05, .1, length = 5)
rej <- NULL
for(alpha in alphaVec){
bot_res <- empOPW(pvalue = pvals, filter = filters, alpha = alpha, tail = 2,
max.group = 15, effectType = "continuous", method = "BH")
rej <- c(rej, bot_res$rejections)
}
rej
optimal_group_df <- function(group = 5L, pvalue, filter, h_breaks = 71L, m, m1,
alpha = .05, mean_testEffect, effectType = c("continuous", "binary"),
method = c("BH", "BON"))
{
optimal_df <- function(df)
{
# ranks probability--------------
ranksProb <- prob_rank_givenEffect_emp(pvalue = pvalue, filter = filter,
group = group, h_breaks = h_breaks, df = df,
effectType = effectType)
# weights-----------
if(effectType == "continuous"){
wgt = weight_continuous(alpha = alpha, et = mean_testEffect,
m = group, ranksProb = ranksProb)
} else {
wgt = weight_binary(alpha = alpha, et = mean_testEffect, m = group,
m1 = m1/m*group, ranksProb = ranksProb)
}
# weight for all test----------
grpSize <- ceiling(m/group)
wgt_all = rep(wgt, each = grpSize)[1:m]
# count number of rejections-----------
if(method == "BH"){
padj <- p.adjust(pvalue/wgt_all, method = method)
n_rejections = sum(padj <= alpha, na.rm = TRUE)
} else {
n_rejections = sum(pvalue <= alpha*wgt_all/m, na.rm = TRUE)
}
return(c(df = df, n_rej = n_rejections))
}
message(paste("computing for group", group))
# not necessary to use all df
df_and_rej <- sapply(seq(2, group, 3), optimal_df)
op_df_rej <- df_and_rej[ , which.max(df_and_rej[2,])]
return(c(group = group, op_df_rej))
}
alphaVec <- seq(.05, .1, length = 5)
rej <- NULL
for(alpha in alphaVec){
bot_res <- empOPW(pvalue = pvals, filter = filters, alpha = alpha, tail = 2,
max.group = 15, effectType = "continuous", method = "BH")
rej <- c(rej, bot_res$rejections)
}
rej
prob_rank_givenEffect_emp <- function(pvalue, filter, group = 5L, h_breaks = 71L,
df = 3, effectType = c("continuous", "binary"))
{
Data = tibble(pvalue, filter)
data_omit_na <- Data[which(!is.na(Data$pvalue)),]
OD <- data_omit_na[order(data_omit_na$filter, decreasing = TRUE), ]
OD_pvalue <- OD$pvalue
grpSize <- ceiling(length(OD_pvalue)/group)
# function to compute ranks probbaility per group--------------
fun_prob <- function(grp)
{
pval_perGrp <- OD_pvalue[(grp*grpSize - grpSize + 1):(grp*grpSize)]
if(effectType == "continuous"){
hist_dens <- hist(pval_perGrp, freq = FALSE,
breaks = seq(0, 1, length = h_breaks))$density
probAll = hist_dens/sum(hist_dens)
prob = probAll[1]
} else {
prob <- 1 - propTrueNull(p = pval_perGrp, method = "lfdr")
}
return(prob)
}
probVec <- sapply(1:group, fun_prob)
# smooting and nomalizing the ranks probability-------------
probVec_smooth <- smooth.spline(x = 1:group, y = probVec, df = df)$y
if(any(probVec_smooth < 0)){
neg_val <- probVec_smooth[probVec_smooth < 0]
probVec_smooth <- probVec_smooth - neg_val
}
probVec_smooth_norm <- probVec_smooth/sum(probVec_smooth, na.rm = TRUE)
return(probVec_smooth_norm)
}
alphaVec <- seq(.05, .1, length = 5)
rej <- NULL
for(alpha in alphaVec){
bot_res <- empOPW(pvalue = pvals, filter = filters, alpha = alpha, tail = 2,
max.group = 15, effectType = "continuous", method = "BH")
rej <- c(rej, bot_res$rejections)
}
rej
bot_res <- empOPW(pvalue = pvals, filter = filters, alpha = .05, tail = 2,
max.group = 15, effectType = "continuous", method = "BH")
warnings()
bot_res
probVec <- bot_res$ranksProb
probVec
probVec_smooth <- bot_res$ranksProb
probVec_smooth
if(any(probVec_smooth < 0)){
neg_val <- probVec_smooth[probVec_smooth < 0]
probVec_smooth <- probVec_smooth - neg_val
}
probVec_smooth
any(probVec_smooth < 0)
probVec_smooth <- bot_res$ranksProb
any(probVec_smooth < 0)
neg_val <- probVec_smooth[probVec_smooth < 0]
neg_val
prob_rank_givenEffect_emp <- function(pvalue, filter, group = 5L, h_breaks = 71L,
df = 3, effectType = c("continuous", "binary"))
{
Data = tibble(pvalue, filter)
data_omit_na <- Data[which(!is.na(Data$pvalue)),]
OD <- data_omit_na[order(data_omit_na$filter, decreasing = TRUE), ]
OD_pvalue <- OD$pvalue
grpSize <- ceiling(length(OD_pvalue)/group)
# function to compute ranks probbaility per group--------------
fun_prob <- function(grp)
{
pval_perGrp <- OD_pvalue[(grp*grpSize - grpSize + 1):(grp*grpSize)]
if(effectType == "continuous"){
hist_dens <- hist(pval_perGrp, freq = FALSE,
breaks = seq(0, 1, length = h_breaks))$density
probAll = hist_dens/sum(hist_dens)
prob = probAll[1]
} else {
prob <- 1 - propTrueNull(p = pval_perGrp, method = "lfdr")
}
return(prob)
}
probVec <- sapply(1:group, fun_prob)
# smooting and nomalizing the ranks probability-------------
probVec_smooth <- smooth.spline(x = 1:group, y = probVec, df = df)$y
if(any(probVec_smooth < 0)){
neg_val <- probVec_smooth[probVec_smooth < 0]
probVec_smooth <- probVec_smooth - neg_val
}
probVec_smooth_norm <- probVec_smooth/sum(probVec_smooth, na.rm = TRUE)
return(probVec_smooth_norm)
}
bot_res <- empOPW(pvalue = pvals, filter = filters, alpha = .05, tail = 2,
max.group = 15, effectType = "continuous", method = "BH")
bot_res
Data = tibble(pvalue, filter)
pvalue = pvals
filter = filters
Data = tibble(pvalue, filter)
data_omit_na <- Data[which(!is.na(Data$pvalue)),]
OD <- data_omit_na[order(data_omit_na$filter, decreasing = TRUE), ]
OD_pvalue <- OD$pvalue
grpSize <- ceiling(length(OD_pvalue)/group)
fun_prob <- function(grp)
{
pval_perGrp <- OD_pvalue[(grp*grpSize - grpSize + 1):(grp*grpSize)]
if(effectType == "continuous"){
hist_dens <- hist(pval_perGrp, freq = FALSE,
breaks = seq(0, 1, length = h_breaks))$density
probAll = hist_dens/sum(hist_dens)
prob = probAll[1]
} else {
prob <- 1 - propTrueNull(p = pval_perGrp, method = "lfdr")
}
return(prob)
}
probVec <- sapply(1:group, fun_prob)
group=15
probVec <- sapply(1:group, fun_prob)
grpSize <- ceiling(length(OD_pvalue)/group)
probVec <- sapply(1:group, fun_prob)
h_breaks = 71L
probVec <- sapply(1:group, fun_prob)
probVec
probVec_smooth <- smooth.spline(x = 1:group, y = probVec, df = df)$y
df = 3
probVec_smooth <- smooth.spline(x = 1:group, y = probVec, df = df)$y
probVec_smooth
if(any(probVec_smooth < 0)){
neg_val <- probVec_smooth[probVec_smooth < 0]
probVec_smooth <- probVec_smooth - neg_val
}
probVec_smooth
Data = tibble(pvalue, filter)
data_omit_na <- Data[which(!is.na(Data$pvalue)),]
OD <- data_omit_na[order(data_omit_na$filter, decreasing = TRUE), ]
OD_pvalue <- OD$pvalue
m = length(OD_pvalue)
nullProp = qvalue(p = OD_pvalue, pi0.method = "bootstrap")$pi0
m0 = ceiling(nullProp*m)
m1 = m - m0
if(!is.null(weight)){
wgt <- weight
} else {
# estimate the mean test effect size-------------
if(!is.null(mean_testEffect)){
mean_testEffect <- mean_testEffect
} else {
# compute test statistics from the pvalues---------
test <- qnorm(pvalue/tail, lower.tail = FALSE)
test[which(!is.finite(test))] <- NA
# estimate the true alterantive test effect sizes----------------
if(m1 == 0){
test_effect_vec <- 0
} else {
test_effect_vec <-  sort(test, decreasing = TRUE)[1:m1]
}
# compute mean test effect----------
if(effectType == "continuous"){
mean_testEffect <- mean(test_effect_vec, na.rm = TRUE)
} else {
mean_testEffect <- median(test_effect_vec, na.rm = TRUE)
}
}
# find the optimal number of groups and degrees of freedom----------
grp_seq <- seq(5, max.group, 5)
op_grp_df <- sapply(grp_seq, optimal_group_df, pvalue = OD$pvalue,
filter = OD$filter, h_breaks = h_breaks, m = m, m1 = m1,
alpha = alpha, mean_testEffect = mean_testEffect,
effectType = effectType, method = method)
grp <- op_grp_df[1, which.max(op_grp_df[3,])]
df <- op_grp_df[2, which.max(op_grp_df[3,])]
message("computing ranks probabilities")
# compute the ranks probability of the tests given the mean effect
ranksProb <- prob_rank_givenEffect_emp(pvalue = pvalue, filter = filter,
group = grp, h_breaks = h_breaks, df = df,
effectType = effectType)
message("finished computing the ranks probabilities")
message("computing weights")
if(effectType == "continuous"){
wgt = weight_continuous(alpha = alpha, et = mean_testEffect,
m = grp, ranksProb = ranksProb)
} else {
wgt = weight_binary(alpha = alpha, et = mean_testEffect, m = grp,
m1 = m1/m*grp, ranksProb = ranksProb)
}
message("finished computing the weights")
}
weight = NULL
ranksProb = NULL
mean_testEffect = NULL
alpha = .05
tail = 1L
delInterval = .0001
max.group = 15
h_breaks = 71L
effectType = "continuous"
method = "BH"
if(!is.null(weight)){
wgt <- weight
} else {
# estimate the mean test effect size-------------
if(!is.null(mean_testEffect)){
mean_testEffect <- mean_testEffect
} else {
# compute test statistics from the pvalues---------
test <- qnorm(pvalue/tail, lower.tail = FALSE)
test[which(!is.finite(test))] <- NA
# estimate the true alterantive test effect sizes----------------
if(m1 == 0){
test_effect_vec <- 0
} else {
test_effect_vec <-  sort(test, decreasing = TRUE)[1:m1]
}
# compute mean test effect----------
if(effectType == "continuous"){
mean_testEffect <- mean(test_effect_vec, na.rm = TRUE)
} else {
mean_testEffect <- median(test_effect_vec, na.rm = TRUE)
}
}
# find the optimal number of groups and degrees of freedom----------
grp_seq <- seq(5, max.group, 5)
op_grp_df <- sapply(grp_seq, optimal_group_df, pvalue = OD$pvalue,
filter = OD$filter, h_breaks = h_breaks, m = m, m1 = m1,
alpha = alpha, mean_testEffect = mean_testEffect,
effectType = effectType, method = method)
grp <- op_grp_df[1, which.max(op_grp_df[3,])]
df <- op_grp_df[2, which.max(op_grp_df[3,])]
message("computing ranks probabilities")
# compute the ranks probability of the tests given the mean effect
ranksProb <- prob_rank_givenEffect_emp(pvalue = pvalue, filter = filter,
group = grp, h_breaks = h_breaks, df = df,
effectType = effectType)
message("finished computing the ranks probabilities")
message("computing weights")
if(effectType == "continuous"){
wgt = weight_continuous(alpha = alpha, et = mean_testEffect,
m = grp, ranksProb = ranksProb)
} else {
wgt = weight_binary(alpha = alpha, et = mean_testEffect, m = grp,
m1 = m1/m*grp, ranksProb = ranksProb)
}
message("finished computing the weights")
}
prob_rank_givenEffect_emp
library(empOPW)
library(empOPW)
library(devtools)
install_github("mshasan/empOPW")
library(empOPW)
simu_fwer <- function(s, m, alphaVec, max.group = 5L)
{
fwer_per_rep <- function(alpha)
{
pval <- runif(m)
pval_filter <- runif(m)
test = qnorm(pval, lower.tail = FALSE)
filter = qnorm(pval_filter, lower.tail = FALSE)
pro_bin <- empOPW(pvalue = dat$pval, filter = dat$filter,
alpha = alpha, max.group = max.group,
effectType = "binary", method = "BON")$rejections
pro_cont<- empOPW(pvalue = dat$pval, filter = dat$filter,
alpha = alpha, max.group = max.group,
effectType = "continuous", method = "BON")$rejections
ihw_fwer <- ihw(dat$pval, dat$filter, alpha = alpha,
adjustment_type = "bonferroni")
bon = sum(pval <= alpha/m, na.rm = TRUE)
IHW <- rejections(ihw_fwer)
return(c(bon, pro_bin, pro_cont, IHW))
}
fwer_per_rep_mat = sapply(alphaVec, fwer_per_rep)
return(fwer_per_rep_mat)
}
alphaVec = seq(.01, .1, .02)
simVal = 1:3  # in actual case use at least simVal = 1000
typeIerror_mat = sapply(simVal, simu_fwer, m = 100, alphaVec = alphaVec)
library(empOPW)
typeIerror_mat = sapply(simVal, simu_fwer, m = 100, alphaVec = alphaVec)
simu_fwer <- function(s, m, alphaVec, max.group = 5L)
{
fwer_per_rep <- function(alpha)
{
pval <- runif(m)
pval_filter <- runif(m)
test = qnorm(pval, lower.tail = FALSE)
filter = qnorm(pval_filter, lower.tail = FALSE)
pro_bin <- empOPW(pvalue = pval, filter = filter,
alpha = alpha, max.group = max.group,
effectType = "binary", method = "BON")$rejections
pro_cont<- empOPW(pvalue = pval, filter = filter,
alpha = alpha, max.group = max.group,
effectType = "continuous", method = "BON")$rejections
ihw_fwer <- ihw(dat$pval, dat$filter, alpha = alpha,
adjustment_type = "bonferroni")
bon = sum(pval <= alpha/m, na.rm = TRUE)
IHW <- rejections(ihw_fwer)
return(c(bon, pro_bin, pro_cont, IHW))
}
fwer_per_rep_mat = sapply(alphaVec, fwer_per_rep)
return(fwer_per_rep_mat)
}
typeIerror_mat = sapply(simVal, simu_fwer, m = 100, alphaVec = alphaVec)
library(IHW)
typeIerror_mat = sapply(simVal, simu_fwer, m = 100, alphaVec = alphaVec)
simu_fwer <- function(s, m, alphaVec, max.group = 5L)
{
fwer_per_rep <- function(alpha)
{
pval <- runif(m)
pval_filter <- runif(m)
test = qnorm(pval, lower.tail = FALSE)
filter = qnorm(pval_filter, lower.tail = FALSE)
pro_bin <- empOPW(pvalue = pval, filter = filter,
alpha = alpha, max.group = max.group,
effectType = "binary", method = "BON")$rejections
pro_cont<- empOPW(pvalue = pval, filter = filter,
alpha = alpha, max.group = max.group,
effectType = "continuous", method = "BON")$rejections
ihw_fwer <- ihw(pval, filter, alpha = alpha,
adjustment_type = "bonferroni")
bon = sum(pval <= alpha/m, na.rm = TRUE)
IHW <- rejections(ihw_fwer)
return(c(bon, pro_bin, pro_cont, IHW))
}
fwer_per_rep_mat = sapply(alphaVec, fwer_per_rep)
return(fwer_per_rep_mat)
}
typeIerror_mat = sapply(simVal, simu_fwer, m = 100, alphaVec = alphaVec)
warnings()
typeIerror_mat
alphaVec = seq(.01, .1, .02)
fwer_mat = sapply(simVal, simu_fwer, m = 10000, alphaVec = alphaVec)
fwer_mat
fwer_by_alpha <- matrix(apply(fwer_mat, 1, mean), nrow = 4, byrow = FALSE)
fwer_by_alpha
library(empOPW)
library(empOPW)
library(devtools)
library(empOPW)
install_github("mshasan/empOPW")
library(empOPW)
library(empOPW)
install.packages(file.choose(), repos=NULL)
