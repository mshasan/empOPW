FDR_ihw <- sum(adjPval_ihw[OD$et == 0] <= alpha)/max(1, rejections(ihw_fdr))
FDR_POWER_pro <- sum(rej_pro_fdr[OD$et != 0])/n_alt
FDR_POWER_bh  <- sum(adjPval_bon[OD$et != 0] <= alpha)/n_alt
FDR_POWER_rdw <- sum(adjPval_rdw[OD$et != 0] <= alpha)/n_alt
FDR_POWER_ihw <- sum(adjPval_ihw[OD$et != 0] <= alpha)/n_alt
return(c(FWER_pro, FWER_bon, FWER_rdw, FWER_ihw,
POWER_pro, POWER_bon, POWER_rdw, POWER_ihw,
FDR_pro, FDR_bh, FDR_rdw, FDR_ihw, FDR_POWER_pro,
FDR_POWER_bh, FDR_POWER_rdw, FDR_POWER_ihw))
}
fwerPowerFdrPower_bysimu <- sapply(1:simu, fwerPowerFdrPower_simu)
fwerPowerFdrPower <- apply(fwerPowerFdrPower_bysimu, 1, mean, na.rm = TRUE)
return(fwerPowerFdrPower)
}
effectVec <- c(seq(0,1,.2),2,3,5,8)
simu = 3
FwerPowerFdrPower <- sapply(1:length(effectVec), fwerPowerFdrPower_emp, simu=simu,
m = 10000, null = .5, corr = 0, cv = 0, alpha = .05,
groupSize = 100, max.group = 10, filterEffectVec = effectVec,
effectType = "continuous")
FwerPowerFdrPower
prob_rank_givenEffect_emp <- function(pvalue, filter, group = 5L, h_breaks = 71L,
df = 3, effectType = c("continuous", "binary"))
{
Data = tibble(pvalue, filter)
data_omit_na <- Data[which(!is.na(Data$pvalue)),]
OD <- data_omit_na[order(data_omit_na$filter, decreasing = TRUE), ]
OD_pvalue <- OD$pvalue
grpSize <- ceiling(length(OD_pvalue)/group)
# function to compute ranks probbaility per group--------------
fun_prob <- function(grp)
{
pval_perGrp <- OD_pvalue[(grp*grpSize - grpSize + 1):(grp*grpSize)]
if(effectType == "continuous"){
hist_dens <- hist(pval_perGrp, freq = FALSE,
breaks = seq(0, 1, length = h_breaks))$density
probAll = hist_dens/sum(hist_dens)
prob = probAll[1]
} else {
prob <- 1 - propTrueNull(p = pval_perGrp, method = "lfdr")
}
return(prob)
}
probVec <- sapply(1:group, fun_prob)
# smooting and nomalizing the ranks probability-------------
probVec_smooth <- smooth.spline(x = 1:group, y = probVec, df = df)$y
if(any(probVec_smooth < 0)){
neg_val <- probVec_smooth[probVec_smooth < 0]
probVec_smooth <- probVec_smooth - neg_val
}
probVec_smooth_norm <- probVec_smooth/sum(probVec_smooth, na.rm = TRUE)
return(probVec_smooth_norm)
}
alphaVec <- seq(.05, .1, length = 5)
rej <- NULL
for(alpha in alphaVec){
bot_res <- empOPW(pvalue = pvals, filter = filters, alpha = alpha, tail = 2,
max.group = 15, effectType = "continuous", method = "BH")
rej <- c(rej, bot_res$rejections)
}
rej
pvals = bottomly$pvalue
setwd("U:/Documents/My Research (UGA)/Multiple Hypoetheses/Article-2")
library(MASS)
library(qvalue)
library(limma)
library(splines)
library(OPWeight)
library(OPWpaper)
library(empOPW)
library(DESeq2)
#install.packages("mvnfast")
library(mvnfast)		# fast generate multi variate normal
#source("https://bioconductor.org/biocLite.R")
#biocLite("IHW")
library("IHW")
bottomly_count_table <- read.table("bottomly_count_table.txt",h=T)
bottomly_phenodata <- read.table("bottomly_phenodata.txt",h=T)
countData <- as.matrix(bottomly_count_table[,-1])		# counts
condition <- factor(bottomly_phenodata[,3])				# strain as factor
dds <- DESeqDataSetFromMatrix(countData, DataFrame(condition), ~ condition)
dds <- DESeq(dds)
bottomly <- results(dds)
colnames(bottomly)
pvals = bottomly$pvalue
filters = bottomly$baseMean
alphaVec <- seq(.05, .1, length = 5)
rej <- NULL
for(alpha in alphaVec){
bot_res <- empOPW(pvalue = pvals, filter = filters, alpha = alpha, tail = 2,
max.group = 15, effectType = "continuous", method = "BH")
rej <- c(rej, bot_res$rejections)
}
rej
prob_rank_givenEffect_emp <- function(pvalue, filter, group = 5L, h_breaks = 71L,
df = 3, effectType = c("continuous", "binary"))
{
Data = tibble(pvalue, filter)
data_omit_na <- Data[which(!is.na(Data$pvalue)),]
OD <- data_omit_na[order(data_omit_na$filter, decreasing = TRUE), ]
OD_pvalue <- OD$pvalue
grpSize <- ceiling(length(OD_pvalue)/group)
# function to compute ranks probbaility per group--------------
fun_prob <- function(grp)
{
pval_perGrp <- OD_pvalue[(grp*grpSize - grpSize + 1):(grp*grpSize)]
if(effectType == "continuous"){
hist_dens <- hist(pval_perGrp, freq = FALSE,
breaks = seq(0, 1, length = h_breaks))$density
probAll = hist_dens/sum(hist_dens)
prob = probAll[1]
} else {
prob <- 1 - propTrueNull(p = pval_perGrp, method = "lfdr")
}
return(prob)
}
probVec <- sapply(1:group, fun_prob)
# smooting and nomalizing the ranks probability-------------
probVec_smooth <- smooth.spline(x = 1:group, y = probVec, df = df)$y
# if(any(probVec_smooth < 0)){
#     neg_val <- probVec_smooth[probVec_smooth < 0]
#     probVec_smooth <- probVec_smooth - neg_val
# }
probVec_smooth_norm <- probVec_smooth/sum(probVec_smooth, na.rm = TRUE)
return(probVec_smooth_norm)
}
alphaVec <- seq(.05, .1, length = 5)
rej <- NULL
for(alpha in alphaVec){
bot_res <- empOPW(pvalue = pvals, filter = filters, alpha = alpha, tail = 2,
max.group = 15, effectType = "continuous", method = "BH")
rej <- c(rej, bot_res$rejections)
}
rej
empOPW <- function(pvalue, filter, weight = NULL, ranksProb = NULL, mean_testEffect = NULL,
alpha = .05, tail = 1L, delInterval = .0001, max.group = 5L, h_breaks = 71L,
effectType = c("continuous", "binary"), method = c("BH", "BON"), ... )
{
# formulate a data set-------------
Data = tibble(pvalue, filter)
data_omit_na <- Data[which(!is.na(Data$pvalue)),]
OD <- data_omit_na[order(data_omit_na$filter, decreasing = TRUE), ]
OD_pvalue <- OD$pvalue
# compute the number of tests------------
m = length(OD_pvalue)
nullProp = qvalue(p = OD_pvalue, pi0.method = "bootstrap")$pi0
m0 = ceiling(nullProp*m)
m1 = m - m0
#check whether weight is provided------------
if(!is.null(weight)){
wgt <- weight
} else {
# estimate the mean test effect size-------------
if(!is.null(mean_testEffect)){
mean_testEffect <- mean_testEffect
} else {
# compute test statistics from the pvalues---------
test <- qnorm(pvalue/tail, lower.tail = FALSE)
test[which(!is.finite(test))] <- NA
# estimate the true alterantive test effect sizes----------------
if(m1 == 0){
test_effect_vec <- 0
} else {
test_effect_vec <-  sort(test, decreasing = TRUE)[1:m1]
}
# compute mean test effect----------
if(effectType == "continuous"){
mean_testEffect <- mean(test_effect_vec, na.rm = TRUE)
} else {
mean_testEffect <- median(test_effect_vec, na.rm = TRUE)
}
}
# find the optimal number of groups and degrees of freedom----------
grp_seq <- seq(5, max.group, 5)
op_grp_df <- sapply(grp_seq, optimal_group_df, pvalue = OD$pvalue,
filter = OD$filter, h_breaks = h_breaks, m = m, m1 = m1,
alpha = alpha, mean_testEffect = mean_testEffect,
effectType = effectType, method = method)
grp <- op_grp_df[1, which.max(op_grp_df[3,])]
df <- op_grp_df[2, which.max(op_grp_df[3,])]
message("computing ranks probabilities")
# compute the ranks probability of the tests given the mean effect
ranksProb <- prob_rank_givenEffect_emp(pvalue = pvalue, filter = filter,
group = grp, h_breaks = h_breaks, df = df,
effectType = effectType)
message("finished computing the ranks probabilities")
message("computing weights")
if(effectType == "continuous"){
wgt = weight_continuous(alpha = alpha, et = mean_testEffect,
m = grp, ranksProb = ranksProb)
} else {
wgt = weight_binary(alpha = alpha, et = mean_testEffect, m = grp,
m1 = m1/m*grp, ranksProb = ranksProb)
}
message("finished computing the weights")
}
grpSize <- ceiling(m/grp)
wgt_all = rep(wgt, each = grpSize)[1:m]
message("comparing pvalues with thresholds")
if(method == "BH"){
padj <- p.adjust(OD_pvalue/wgt_all, method = "BH")
rejections_list = OD[which((padj <= alpha) == TRUE), ]
} else {
rejections_list = OD[which((OD_pvalue <= alpha*wgt_all/m) == TRUE), ]
}
# outputs--------------
n_rejections = dim(rejections_list)[1]
return(list(totalTests = length(pvalue), nullProp = nullProp,
ranksProb = ranksProb, weight = wgt_all,
rejections = n_rejections, rejections_list = rejections_list))
}
alphaVec <- seq(.05, .1, length = 5)
rej <- NULL
for(alpha in alphaVec){
bot_res <- empOPW(pvalue = pvals, filter = filters, alpha = alpha, tail = 2,
max.group = 15, effectType = "continuous", method = "BH")
rej <- c(rej, bot_res$rejections)
}
rej
optimal_group_df <- function(group = 5L, pvalue, filter, h_breaks = 71L, m, m1,
alpha = .05, mean_testEffect, effectType = c("continuous", "binary"),
method = c("BH", "BON"))
{
optimal_df <- function(df)
{
# ranks probability--------------
ranksProb <- prob_rank_givenEffect_emp(pvalue = pvalue, filter = filter,
group = group, h_breaks = h_breaks, df = df,
effectType = effectType)
# weights-----------
if(effectType == "continuous"){
wgt = weight_continuous(alpha = alpha, et = mean_testEffect,
m = group, ranksProb = ranksProb)
} else {
wgt = weight_binary(alpha = alpha, et = mean_testEffect, m = group,
m1 = m1/m*group, ranksProb = ranksProb)
}
# weight for all test----------
grpSize <- ceiling(m/group)
wgt_all = rep(wgt, each = grpSize)[1:m]
# count number of rejections-----------
if(method == "BH"){
padj <- p.adjust(pvalue/wgt_all, method = method)
n_rejections = sum(padj <= alpha, na.rm = TRUE)
} else {
n_rejections = sum(pvalue <= alpha*wgt_all/m, na.rm = TRUE)
}
return(c(df = df, n_rej = n_rejections))
}
message(paste("computing for group", group))
# not necessary to use all df
df_and_rej <- sapply(seq(2, group, 3), optimal_df)
op_df_rej <- df_and_rej[ , which.max(df_and_rej[2,])]
return(c(group = group, op_df_rej))
}
alphaVec <- seq(.05, .1, length = 5)
rej <- NULL
for(alpha in alphaVec){
bot_res <- empOPW(pvalue = pvals, filter = filters, alpha = alpha, tail = 2,
max.group = 15, effectType = "continuous", method = "BH")
rej <- c(rej, bot_res$rejections)
}
rej
prob_rank_givenEffect_emp <- function(pvalue, filter, group = 5L, h_breaks = 71L,
df = 3, effectType = c("continuous", "binary"))
{
Data = tibble(pvalue, filter)
data_omit_na <- Data[which(!is.na(Data$pvalue)),]
OD <- data_omit_na[order(data_omit_na$filter, decreasing = TRUE), ]
OD_pvalue <- OD$pvalue
grpSize <- ceiling(length(OD_pvalue)/group)
# function to compute ranks probbaility per group--------------
fun_prob <- function(grp)
{
pval_perGrp <- OD_pvalue[(grp*grpSize - grpSize + 1):(grp*grpSize)]
if(effectType == "continuous"){
hist_dens <- hist(pval_perGrp, freq = FALSE,
breaks = seq(0, 1, length = h_breaks))$density
probAll = hist_dens/sum(hist_dens)
prob = probAll[1]
} else {
prob <- 1 - propTrueNull(p = pval_perGrp, method = "lfdr")
}
return(prob)
}
probVec <- sapply(1:group, fun_prob)
# smooting and nomalizing the ranks probability-------------
probVec_smooth <- smooth.spline(x = 1:group, y = probVec, df = df)$y
if(any(probVec_smooth < 0)){
neg_val <- probVec_smooth[probVec_smooth < 0]
probVec_smooth <- probVec_smooth - neg_val
}
probVec_smooth_norm <- probVec_smooth/sum(probVec_smooth, na.rm = TRUE)
return(probVec_smooth_norm)
}
alphaVec <- seq(.05, .1, length = 5)
rej <- NULL
for(alpha in alphaVec){
bot_res <- empOPW(pvalue = pvals, filter = filters, alpha = alpha, tail = 2,
max.group = 15, effectType = "continuous", method = "BH")
rej <- c(rej, bot_res$rejections)
}
rej
bot_res <- empOPW(pvalue = pvals, filter = filters, alpha = .05, tail = 2,
max.group = 15, effectType = "continuous", method = "BH")
warnings()
bot_res
probVec <- bot_res$ranksProb
probVec
probVec_smooth <- bot_res$ranksProb
probVec_smooth
if(any(probVec_smooth < 0)){
neg_val <- probVec_smooth[probVec_smooth < 0]
probVec_smooth <- probVec_smooth - neg_val
}
probVec_smooth
any(probVec_smooth < 0)
probVec_smooth <- bot_res$ranksProb
any(probVec_smooth < 0)
neg_val <- probVec_smooth[probVec_smooth < 0]
neg_val
prob_rank_givenEffect_emp <- function(pvalue, filter, group = 5L, h_breaks = 71L,
df = 3, effectType = c("continuous", "binary"))
{
Data = tibble(pvalue, filter)
data_omit_na <- Data[which(!is.na(Data$pvalue)),]
OD <- data_omit_na[order(data_omit_na$filter, decreasing = TRUE), ]
OD_pvalue <- OD$pvalue
grpSize <- ceiling(length(OD_pvalue)/group)
# function to compute ranks probbaility per group--------------
fun_prob <- function(grp)
{
pval_perGrp <- OD_pvalue[(grp*grpSize - grpSize + 1):(grp*grpSize)]
if(effectType == "continuous"){
hist_dens <- hist(pval_perGrp, freq = FALSE,
breaks = seq(0, 1, length = h_breaks))$density
probAll = hist_dens/sum(hist_dens)
prob = probAll[1]
} else {
prob <- 1 - propTrueNull(p = pval_perGrp, method = "lfdr")
}
return(prob)
}
probVec <- sapply(1:group, fun_prob)
# smooting and nomalizing the ranks probability-------------
probVec_smooth <- smooth.spline(x = 1:group, y = probVec, df = df)$y
if(any(probVec_smooth < 0)){
neg_val <- probVec_smooth[probVec_smooth < 0]
probVec_smooth <- probVec_smooth - neg_val
}
probVec_smooth_norm <- probVec_smooth/sum(probVec_smooth, na.rm = TRUE)
return(probVec_smooth_norm)
}
bot_res <- empOPW(pvalue = pvals, filter = filters, alpha = .05, tail = 2,
max.group = 15, effectType = "continuous", method = "BH")
bot_res
Data = tibble(pvalue, filter)
pvalue = pvals
filter = filters
Data = tibble(pvalue, filter)
data_omit_na <- Data[which(!is.na(Data$pvalue)),]
OD <- data_omit_na[order(data_omit_na$filter, decreasing = TRUE), ]
OD_pvalue <- OD$pvalue
grpSize <- ceiling(length(OD_pvalue)/group)
fun_prob <- function(grp)
{
pval_perGrp <- OD_pvalue[(grp*grpSize - grpSize + 1):(grp*grpSize)]
if(effectType == "continuous"){
hist_dens <- hist(pval_perGrp, freq = FALSE,
breaks = seq(0, 1, length = h_breaks))$density
probAll = hist_dens/sum(hist_dens)
prob = probAll[1]
} else {
prob <- 1 - propTrueNull(p = pval_perGrp, method = "lfdr")
}
return(prob)
}
probVec <- sapply(1:group, fun_prob)
group=15
probVec <- sapply(1:group, fun_prob)
grpSize <- ceiling(length(OD_pvalue)/group)
probVec <- sapply(1:group, fun_prob)
h_breaks = 71L
probVec <- sapply(1:group, fun_prob)
probVec
probVec_smooth <- smooth.spline(x = 1:group, y = probVec, df = df)$y
df = 3
probVec_smooth <- smooth.spline(x = 1:group, y = probVec, df = df)$y
probVec_smooth
if(any(probVec_smooth < 0)){
neg_val <- probVec_smooth[probVec_smooth < 0]
probVec_smooth <- probVec_smooth - neg_val
}
probVec_smooth
Data = tibble(pvalue, filter)
data_omit_na <- Data[which(!is.na(Data$pvalue)),]
OD <- data_omit_na[order(data_omit_na$filter, decreasing = TRUE), ]
OD_pvalue <- OD$pvalue
m = length(OD_pvalue)
nullProp = qvalue(p = OD_pvalue, pi0.method = "bootstrap")$pi0
m0 = ceiling(nullProp*m)
m1 = m - m0
if(!is.null(weight)){
wgt <- weight
} else {
# estimate the mean test effect size-------------
if(!is.null(mean_testEffect)){
mean_testEffect <- mean_testEffect
} else {
# compute test statistics from the pvalues---------
test <- qnorm(pvalue/tail, lower.tail = FALSE)
test[which(!is.finite(test))] <- NA
# estimate the true alterantive test effect sizes----------------
if(m1 == 0){
test_effect_vec <- 0
} else {
test_effect_vec <-  sort(test, decreasing = TRUE)[1:m1]
}
# compute mean test effect----------
if(effectType == "continuous"){
mean_testEffect <- mean(test_effect_vec, na.rm = TRUE)
} else {
mean_testEffect <- median(test_effect_vec, na.rm = TRUE)
}
}
# find the optimal number of groups and degrees of freedom----------
grp_seq <- seq(5, max.group, 5)
op_grp_df <- sapply(grp_seq, optimal_group_df, pvalue = OD$pvalue,
filter = OD$filter, h_breaks = h_breaks, m = m, m1 = m1,
alpha = alpha, mean_testEffect = mean_testEffect,
effectType = effectType, method = method)
grp <- op_grp_df[1, which.max(op_grp_df[3,])]
df <- op_grp_df[2, which.max(op_grp_df[3,])]
message("computing ranks probabilities")
# compute the ranks probability of the tests given the mean effect
ranksProb <- prob_rank_givenEffect_emp(pvalue = pvalue, filter = filter,
group = grp, h_breaks = h_breaks, df = df,
effectType = effectType)
message("finished computing the ranks probabilities")
message("computing weights")
if(effectType == "continuous"){
wgt = weight_continuous(alpha = alpha, et = mean_testEffect,
m = grp, ranksProb = ranksProb)
} else {
wgt = weight_binary(alpha = alpha, et = mean_testEffect, m = grp,
m1 = m1/m*grp, ranksProb = ranksProb)
}
message("finished computing the weights")
}
weight = NULL
ranksProb = NULL
mean_testEffect = NULL
alpha = .05
tail = 1L
delInterval = .0001
max.group = 15
h_breaks = 71L
effectType = "continuous"
method = "BH"
if(!is.null(weight)){
wgt <- weight
} else {
# estimate the mean test effect size-------------
if(!is.null(mean_testEffect)){
mean_testEffect <- mean_testEffect
} else {
# compute test statistics from the pvalues---------
test <- qnorm(pvalue/tail, lower.tail = FALSE)
test[which(!is.finite(test))] <- NA
# estimate the true alterantive test effect sizes----------------
if(m1 == 0){
test_effect_vec <- 0
} else {
test_effect_vec <-  sort(test, decreasing = TRUE)[1:m1]
}
# compute mean test effect----------
if(effectType == "continuous"){
mean_testEffect <- mean(test_effect_vec, na.rm = TRUE)
} else {
mean_testEffect <- median(test_effect_vec, na.rm = TRUE)
}
}
# find the optimal number of groups and degrees of freedom----------
grp_seq <- seq(5, max.group, 5)
op_grp_df <- sapply(grp_seq, optimal_group_df, pvalue = OD$pvalue,
filter = OD$filter, h_breaks = h_breaks, m = m, m1 = m1,
alpha = alpha, mean_testEffect = mean_testEffect,
effectType = effectType, method = method)
grp <- op_grp_df[1, which.max(op_grp_df[3,])]
df <- op_grp_df[2, which.max(op_grp_df[3,])]
message("computing ranks probabilities")
# compute the ranks probability of the tests given the mean effect
ranksProb <- prob_rank_givenEffect_emp(pvalue = pvalue, filter = filter,
group = grp, h_breaks = h_breaks, df = df,
effectType = effectType)
message("finished computing the ranks probabilities")
message("computing weights")
if(effectType == "continuous"){
wgt = weight_continuous(alpha = alpha, et = mean_testEffect,
m = grp, ranksProb = ranksProb)
} else {
wgt = weight_binary(alpha = alpha, et = mean_testEffect, m = grp,
m1 = m1/m*grp, ranksProb = ranksProb)
}
message("finished computing the weights")
}
prob_rank_givenEffect_emp
library(empOPW)
library(empOPW)
library(devtools)
install_github("mshasan/empOPW")
library(empOPW)
