message("finding optimal number of groups")
if(is.null(group) & is.null(max.group)){
stop("either group or max.group must be provided")
} else if(!is.null(group) & is.null(max.group)){
grp <- group
} else {
# find optimal number of groups ----------
if(max.group <= 10){
grp_seq <- seq(5, max.group, 1)
} else if(max.group <= 30) {
grp_seq <- seq(5, max.group, 2)
} else {
grp_seq <- round(seq(5, max.group, 5))
}
op_grp <- sapply(grp_seq, optimal_group, pvalue = OD$pvalue,
filter = OD$filter, h_breaks = h_breaks, m = m, m1 = m1,
alpha = alpha, mean_testEffect = mean_testEffect,
effectType = effectType, method = method)
grp <- op_grp[[1, which.max(op_grp[2,])]]
}
message("computing ranks probabilities")
# compute the ranks probability of the tests given the mean effect
ranksProb <- prob_rank_givenEffect_emp(pvalue = pvalue, filter = filter,
group = grp, h_breaks = h_breaks, effectType = effectType)
message("computing weights")
if(effectType == "continuous"){
wgt = weight_continuous(alpha = alpha, et = mean_testEffect,
m = grp, ranksProb = ranksProb)
} else {
wgt = weight_binary(alpha = alpha, et = mean_testEffect, m = grp,
m1 = m1/m*grp, ranksProb = ranksProb)
}
}
method = "BON"
if(!is.null(weight)){
wgt <- weight
} else {
# estimate the mean test effect size-------------
if(!is.null(mean_testEffect)){
mean_testEffect <- mean_testEffect
} else {
# compute test statistics from the pvalues---------
test <- qnorm(pvalue/tail, lower.tail = FALSE)
test[which(!is.finite(test))] <- NA
# estimate the true alterantive test effect sizes----------------
if(m1 == 0){
test_effect_vec <- 0
} else {
test_effect_vec <-  sort(test, decreasing = TRUE)[1:m1]
}
# compute mean test effect----------
if(effectType == "continuous"){
mean_testEffect <- mean(test_effect_vec, na.rm = TRUE)
} else {
mean_testEffect <- median(test_effect_vec, na.rm = TRUE)
}
}
# finding group-----------
message("finding optimal number of groups")
if(is.null(group) & is.null(max.group)){
stop("either group or max.group must be provided")
} else if(!is.null(group) & is.null(max.group)){
grp <- group
} else {
# find optimal number of groups ----------
if(max.group <= 10){
grp_seq <- seq(5, max.group, 1)
} else if(max.group <= 30) {
grp_seq <- seq(5, max.group, 2)
} else {
grp_seq <- round(seq(5, max.group, 5))
}
op_grp <- sapply(grp_seq, optimal_group, pvalue = OD$pvalue,
filter = OD$filter, h_breaks = h_breaks, m = m, m1 = m1,
alpha = alpha, mean_testEffect = mean_testEffect,
effectType = effectType, method = method)
grp <- op_grp[[1, which.max(op_grp[2,])]]
}
message("computing ranks probabilities")
# compute the ranks probability of the tests given the mean effect
ranksProb <- prob_rank_givenEffect_emp(pvalue = pvalue, filter = filter,
group = grp, h_breaks = h_breaks, effectType = effectType)
message("computing weights")
if(effectType == "continuous"){
wgt = weight_continuous(alpha = alpha, et = mean_testEffect,
m = grp, ranksProb = ranksProb)
} else {
wgt = weight_binary(alpha = alpha, et = mean_testEffect, m = grp,
m1 = m1/m*grp, ranksProb = ranksProb)
}
}
wgt
simVal = 1  # in actual case use at least simVal = 1000
set.seed(123)
typeIerror_mat = sapply(simVal, simu_fwer_emp, m = 10000, alphaVec = .05)
alpha
m
filters = de_res_air$baseMean
pvals <- de_res_air$pvalue
m = length(pvals)
m
dbn_wgt <- bayes_weights(mu = filters, sigma = rep(1, m), q = alpha/m)$w
rej_dbn <- OD$pval <= alpha*dbn_wgt/m
rej_dbn <- sum(pvals <= alpha*dbn_wgt/m)
rej_dbn
rej_dbn <- sum(pvals <= alpha*dbn_wgt/m, na.rm = TRUE)
rej_dbn
sum(dbn_wgt)
plot(dbn_wgt)
filters = de_res_air$baseMean
pvals <- de_res_air$pvalue
m = length(pvals)
dbn_wgt <- bayes_weights(mu = filters, sigma = rep(1, m), q = alpha/m)$w
sum(dbn_wgt)
rej_dbn <- sum(pvals <= alpha*dbn_wgt/m, na.rm = TRUE)
rej_dbn
alpha
sum(p.adjust(pvals/dbn_wgt, method = "BH") <= alpha, na.rm = TRUE)
zscores <- (filters - mean(filters, na.rm = TRUE))/sd(filters, na.rm = TRUE)
dbn_wgt <- bayes_weights(mu = zscores, sigma = rep(1, m), q = alpha/m)$w
sum(dbn_wgt)
rej_dbn <- sum(pvals <= alpha*dbn_wgt/m, na.rm = TRUE)
rej_dbn_bh <- sum(p.adjust(pvals/dbn_wgt, method = "BH") <= alpha, na.rm = TRUE)
rej_dbn
rej_dbn_bh
air_res <- empOPW(pvalue = pvals, filter = filters, alpha = .1, tail = 2,
delInterval = .01, max.group = 145,
effectType = "continuous", method = "BH")
air_res$rejections
air_res$opGroup
air_res <- empOPW(pvalue = pvals, filter = filters, alpha = .1, tail = 2,
delInterval = .01, max.group = 100,
effectType = "continuous", method = "BON")
air_res$rejections
air_res$opGroup
rm(list=ls())
data("airway", package = "airway")
dds <- DESeqDataSet(se = airway, design = ~ cell + dex)
dds <- DESeq(dds)
de_res_air <- results(dds)
colnames(de_res_air)
dim(de_res_air)
filters = de_res_air$baseMean
pvals <- de_res_air$pvalue
m = length(pvals)
air_res <- empOPW(pvalue = pvals, filter = filters, alpha = .1, tail = 2,
delInterval = .01, max.group = 35,
effectType = "continuous", method = "BON")
air_res$rejections
air_res$opGroup
warnings()
air_res <- empOPW(pvalue = pvals, filter = filters, alpha = .1, tail = 2,
delInterval = .01, max.group = 35,
effectType = "continuous", method = "BH")
air_res$rejections
air_res$opGroup
air_res$nullProp
air_res$ranksProb
probVec_smooth=air_res$ranksProb
any(probVec_smooth < 0)
probVec_smooth[probVec_smooth < 0]
min(probVec_smooth[probVec_smooth < 0])
pmin(probVec_smooth[probVec_smooth < 0])
neg_val <- min(probVec_smooth[probVec_smooth < 0])
neg_val
probVec_smooth <- probVec_smooth - neg_val
probVec_smooth
any(probVec_smooth < 0)
min(c(1,2)
)
min(1)
library(empOPW)
install_github("mshasan/empOPW")
prob_rank_givenEffect_emp
air_res <- empOPW(pvalue = pvals, filter = filters, alpha = .1, tail = 2,
delInterval = .01, max.group = 35,
effectType = "continuous", method = "BH")
air_res$rejections
air_res$opGroup
air_res <- empOPW(pvalue = pvals, filter = filters, alpha = .1, tail = 2,
delInterval = .01, max.group = 35,
effectType = "continuous", method = "BON")
air_res$rejections
air_res$opGroup
air_res <- empOPW(pvalue = pvals, filter = filters, alpha = .1, tail = 2,
delInterval = .01, max.group = 35,
effectType = "continuous", method = "BH")
air_res$rejections
air_res$opGroup
zscores <- (filters - mean(filters, na.rm = TRUE))/sd(filters, na.rm = TRUE)
dbn_wgt <- bayes_weights(mu = zscores, sigma = rep(1, m), q = alpha/m)$w
alpha = .1
zscores <- (filters - mean(filters, na.rm = TRUE))/sd(filters, na.rm = TRUE)
dbn_wgt <- bayes_weights(mu = zscores, sigma = rep(1, m), q = alpha/m)$w
sum(dbn_wgt)
rej_dbn <- sum(pvals <= alpha*dbn_wgt/m, na.rm = TRUE)
rej_dbn_bh <- sum(p.adjust(pvals/dbn_wgt, method = "BH") <= alpha, na.rm = TRUE)
rej_dbn
rej_dbn_bh
IHW <- ihw(pvals, filters, alpha = .1, adjustment_type = "bonferroni")
rejections(IHW)
IHW <- ihw(pvals, filters, alpha = .1)
rejections(IHW)
library("pasilla")
dds <- DESeqDataSet(se = pasilla, design = ~ cell + dex)
data("pasillaGenes", package="pasilla")
library("DESeq2")
data("pasillaGenes", package="pasilla")
install.packages("DESeq")
source("https://bioconductor.org/biocLite.R")
biocLite("DESeq")
library("DESeq")
data("pasillaGenes", package="pasilla")
dds <- DESeqDataSet(se = pasilla, design = ~ cell + dex)
dds <- DESeqDataSet(se = pasilla, design = ~ cell + dex)
dds <- DESeqDataSet(se = "pasilla", design = ~ cell + dex)
dds <- DESeqDataSet(se = pasillaGenes, design = ~ cell + dex)
countData <- counts(pasillaGenes)
countData
colData <- pData(pasillaGenes)[,c("condition","type")]
dds <- DESeqDataSetFromMatrix(countData = countData,
colData = colData,
design = ~ condition)
dds <- DESeq(dds)
de_res_pas <- results(dds)
colnames(de_res_pas)
dim(de_res_pas)
filters = de_res_pas$baseMean
pvals <- de_res_pas$pvalue
m = length(pvals)
m
pas_res <- empOPW(pvalue = pvals, filter = filters, alpha = .1, tail = 2,
delInterval = .01, max.group = 35,
effectType = "continuous", method = "BH")
pas_res$rejections
pas_res$opGroup
IHW <- ihw(pvals, filters, alpha = .1, adjustment_type = "bonferroni")
rejections(IHW)
IHW <- ihw(pvals, filters, alpha = .1)
rejections(IHW)
pas_res <- empOPW(pvalue = pvals, filter = filters, alpha = .1, tail = 2,
delInterval = .01, max.group = 100,
effectType = "continuous", method = "BH")
pas_res$rejections
pas_res$opGroup
pas_res <- empOPW(pvalue = pvals, filter = filters, alpha = .1, tail = 2,
delInterval = .01, max.group = 100,
effectType = "continuous", method = "BON")
pas_res$rejections
pas_res$opGroup
alpha = .1
zscores <- (filters - mean(filters, na.rm = TRUE))/sd(filters, na.rm = TRUE)
dbn_wgt <- bayes_weights(mu = zscores, sigma = rep(1, m), q = alpha/m)$w
sum(dbn_wgt)
rej_dbn <- sum(pvals <= alpha*dbn_wgt/m, na.rm = TRUE)
rej_dbn_bh <- sum(p.adjust(pvals/dbn_wgt, method = "BH") <= alpha, na.rm = TRUE)
rej_dbn
rej_dbn_bh
load(system.file("extdata/real_data", "hammer_eset.RData", package = "IHWpaper"),
envir=environment())
countData <- exprs(hammer.eset)
colData <- pData(hammer.eset)
dds <- DESeqDataSetFromMatrix(countData = countData, colData = colData , design = ~protocol)
dds <- dds[, dds$Time == "2 months"]
dds <- DESeq(dds)
de_res_ham <- results(dds)
colnames(de_res_ham)
dim(de_res_ham)
filters = de_res_ham$baseMean
pvals <- de_res_ham$pvalue
m = length(pvals)
m
ham_res <- empOPW(pvalue = pvals, filter = filters, alpha = .1, tail = 2,
delInterval = .01, max.group = 100,
effectType = "continuous", method = "BON")
ham_res$rejections
ham_res$opGroup
IHW <- ihw(pvals, filters, alpha = .1)
rejections(IHW)
IHW <- ihw(pvals, filters, alpha = .1, adjustment_type = "bonferroni")
rejections(IHW)
alpha = .1
zscores <- (filters - mean(filters, na.rm = TRUE))/sd(filters, na.rm = TRUE)
sum(dbn_wgt)
rej_dbn <- sum(pvals <= alpha*dbn_wgt/m, na.rm = TRUE)
dbn_wgt <- bayes_weights(mu = zscores, sigma = rep(1, m), q = alpha/m)$w
rej_dbn_bh <- sum(p.adjust(pvals/dbn_wgt, method = "BH") <= alpha, na.rm = TRUE)
filters = de_res_ham$baseMean
pvals <- de_res_ham$pvalue
m = length(pvals)
zscores <- (filters - mean(filters, na.rm = TRUE))/sd(filters, na.rm = TRUE)
dbn_wgt <- bayes_weights(mu = zscores, sigma = rep(1, m), q = alpha/m)$w
sum(dbn_wgt)
rej_dbn <- sum(pvals <= alpha*dbn_wgt/m, na.rm = TRUE)
rej_dbn_bh <- sum(p.adjust(pvals/dbn_wgt, method = "BH") <= alpha, na.rm = TRUE)
rej_dbn_bh
rej_dbn
ham_res <- empOPW(pvalue = pvals, filter = filters, alpha = .1, tail = 2,
delInterval = .01, max.group = 200,
effectType = "continuous", method = "BON")
ham_res$rejections
ham_res$opGroup
ham_res <- empOPW(pvalue = pvals, filter = filters, alpha = .1, tail = 2,
delInterval = .01, max.group = 200,
effectType = "continuous", method = "BH")
ham_res$rejections
ham_res$opGroup
ham_res <- empOPW(pvalue = pvals, filter = filters, alpha = .1, tail = 2,
delInterval = .01, max.group = 200,
effectType = "continuous", method = "BON")
pvalue=pvals
filter=filters
Data = tibble(pvalue, filter)
data_omit_na <- Data[which(!is.na(Data$pvalue)),]
OD <- data_omit_na[order(data_omit_na$filter, decreasing = TRUE), ]
OD_pvalue <- OD$pvalue
OD_pvalue
grpSize <- ceiling(length(OD_pvalue)/group)
group = 5L
grpSize <- ceiling(length(OD_pvalue)/group)
grpSize
fun_prob <- function(grp)
{
pval_perGrp <- OD_pvalue[(grp*grpSize - grpSize + 1):(grp*grpSize)]
if(effectType == "continuous"){
prob <- relative_freq(bin_idx = bin_idx, h_breaks = h_breaks,
obs = pval_perGrp)$rf_one
} else {
prob <- 1 - propTrueNull(p = pval_perGrp, method = "hist")
}
return(prob)
}
probVec <- sapply(1:group, fun_prob)
effectType="continuous"
probVec <- sapply(1:group, fun_prob)
h_breaks = 100L
bin_idx = 1L
probVec <- sapply(1:group, fun_prob)
probVec
grpSize <- ceiling(length(OD_pvalue)/20)
group=20
grpSize <- ceiling(length(OD_pvalue)/group)
probVec <- sapply(1:group, fun_prob)
probVec
group=30
group=30
grpSize <- ceiling(length(OD_pvalue)/group)
probVec <- sapply(1:group, fun_prob)
probVec
group=40
grpSize <- ceiling(length(OD_pvalue)/group)
probVec <- sapply(1:group, fun_prob)
probVec
group=50
grpSize <- ceiling(length(OD_pvalue)/group)
probVec <- sapply(1:group, fun_prob)
probVec
group=60
grpSize <- ceiling(length(OD_pvalue)/group)
probVec <- sapply(1:group, fun_prob)
probVec
group=70
grpSize <- ceiling(length(OD_pvalue)/group)
probVec <- sapply(1:group, fun_prob)
probVec
group=100
grpSize <- ceiling(length(OD_pvalue)/group)
probVec <- sapply(1:group, fun_prob)
probVec
probVec_smooth <- smooth.spline(x = 1:group, y = probVec, cv = FALSE)$y
ham_res <- empOPW(pvalue = pvals, filter = filters, alpha = .1, tail = 2,
delInterval = .01, max.group = 100,
effectType = "continuous", method = "BH")
ham_res$rejections
ham_res$opGroup
rm(list=ls())
load(system.file("extdata/real_data", "hammer_eset.RData", package = "IHWpaper"),
envir=environment())
countData <- exprs(hammer.eset)
colData <- pData(hammer.eset)
dds <- DESeqDataSetFromMatrix(countData = countData, colData = colData , design = ~protocol)
dds <- dds[, dds$Time == "2 months"]
dds <- DESeq(dds)
de_res_ham <- results(dds)
colnames(de_res_ham)
dim(de_res_ham)
filters = de_res_ham$baseMean
pvals <- de_res_ham$pvalue
m = length(pvals)
ham_res <- empOPW(pvalue = pvals, filter = filters, alpha = .1, tail = 2,
delInterval = .01, max.group = 100,
effectType = "continuous", method = "BH")
ham_res$rejections
ham_res$opGroup
ham_res <- empOPW(pvalue = pvals, filter = filters, alpha = .1, tail = 2,
delInterval = .01, max.group = 100,
effectType = "continuous", method = "BON")
ham_res$rejections
ham_res$opGroup
X = runif(1000, min = 0, max = 2)         # covariate
bin_idx = 1L
h_breaks = 20L
obs = X
bin <- c(0, (1:h_breaks)/h_breaks)
bin
bin.counts <- tabulate(cut(obs, bin))
bin.counts
bin.counts[5] <- 0
bin.counts
bin.counts/sum(bin.counts)
sum(bin.counts)
rel_freq_all = bin.counts/sum(bin.counts)
rel_freq_all
1:h_breaks
h_breaks
c(0, (1:h_breaks)/h_breaks)
TG_ONE_Eur_tbl <- read_delim("TG_ONE_Eur.tbl.sorted","\t", escape_double = FALSE, trim_ws = TRUE)
setwd("U:/Documents/My Research (UGA)/Multiple Hypoetheses/Article-2")
library(readr)
TG_ONE_Eur_tbl <- read_delim("TG_ONE_Eur.tbl.sorted","\t", escape_double = FALSE, trim_ws = TRUE)
pgc_scz_full_2012_04 <- read.table("pgc.scz.full.2012-04.txt", h = TRUE)
View(pgc_scz_full_2012_04)
View(TG_ONE_Eur_tbl)
filter_pvals <- TG_ONE_Eur_tbl$GC.Pvalue[pmatch(commonSnp, TG_ONE_Eur_tbl$MarkerName)]
commonSnp <- intersect(TG_ONE_Eur_tbl$MarkerName, pgc_scz_full_2012_04$snpid)
filter_pvals <- TG_ONE_Eur_tbl$GC.Pvalue[pmatch(commonSnp, TG_ONE_Eur_tbl$MarkerName)]
pvals <- pgc_scz_full_2012_04$pval[pmatch(commonSnp, pgc_scz_full_2012_04$snpid)]
filters <- qnorm(filter_pvals/2, lower.tail = FALSE)
lipid_res <- empOPW(pvalue = pvals, filter = filters, alpha = alpha, tail = 2,
delInterval = .01, max.group = 100,
effectType = "binary", method = "BON")
lipid_res$rejections
alpha = .1
lipid_res <- empOPW(pvalue = pvals, filter = filters, alpha = alpha, tail = 2,
delInterval = .01, max.group = 100,
effectType = "binary", method = "BON")
lipid_res$rejections
lipid_res$opGroup
lipid_res <- empOPW(pvalue = pvals, filter = filters, alpha = alpha, tail = 2,
delInterval = .01, max.group = 100,
effectType = "binary", method = "BH")
lipid_res$rejections
lipid_res$opGroup
f
zscores <- filters
m = length(pvals)
dbn_wgt <- bayes_weights(mu = zscores, sigma = rep(1, m), q = alpha/m)$w
sum(dbn_wgt)
m
rej_dbn <- sum(pvals <= alpha*dbn_wgt/m, na.rm = TRUE)
rej_dbn_bh <- sum(p.adjust(pvals/dbn_wgt, method = "BH") <= alpha, na.rm = TRUE)
rej_dbn
rej_dbn_bh
setwd("U:/Documents/My Research (UGA)/Multiple Hypoetheses/Article-2/Data")
library(readr)
library(readr)
CKDGen_eGFRcrea_meta_post <- read_csv("U:/Documents/My Research (UGA)/Multiple Hypoetheses/Article-2/Data/CKDGen-eGFRcrea_meta_post.csv")
View(CKDGen_eGFRcrea_meta_post)
library(readr)
C4D_CAD_DISCOVERY_METAANALYSIS_UPDATE <- read_delim("U:/Documents/My Research (UGA)/Multiple Hypoetheses/Article-2/Data/C4D_CAD_DISCOVERY_METAANALYSIS_UPDATE.TXT",
"\t", escape_double = FALSE, trim_ws = TRUE)
View(C4D_CAD_DISCOVERY_METAANALYSIS_UPDATE)
CKDGen <- read_csv("CKDGen-eGFRcrea_meta_post.csv")
C4D_CAD <- read_delim("C4D_CAD_DISCOVERY_METAANALYSIS_UPDATE.TXT",
"\t", escape_double = FALSE, trim_ws = TRUE)
commonSnp <- intersect(C4D_CAD$SNP, CKDGen$rsID)
filter_pvals <- CKDGen$pval[pmatch(commonSnp, CKDGen$rsID)]
filter_pvals <- CKDGen$pval[pmatch(commonSnp, CKDGen$rsID)]
pvals <- C4D_CAD$PVALUE[pmatch(commonSnp, C4D_CAD$SNP)]
filters <- qnorm(filter_pvals/2, lower.tail = FALSE)
m = length(pvals)
m
lipid_res <- empOPW(pvalue = pvals, filter = filters, alpha = alpha, tail = 2,
delInterval = .01, max.group = 100,
effectType = "binary", method = "BH")
library(empOPW)
library(pweight)
library(IHW)
lipid_res <- empOPW(pvalue = pvals, filter = filters, alpha = alpha, tail = 2,
delInterval = .01, max.group = 100,
effectType = "binary", method = "BH")
alpha = .1
lipid_res <- empOPW(pvalue = pvals, filter = filters, alpha = alpha, tail = 2,
delInterval = .01, max.group = 100,
effectType = "binary", method = "BH")
lipid_res <- empOPW(pvalue = pvals, filter = filters, alpha = alpha, tail = 2,
delInterval = .01, max.group = 100,
effectType = "continuous", method = "BH")
lipid_res$rejections
lipid_res$opGroup
IHW <- ihw(pvals, filters, alpha = alpha)
rejections(IHW)
IHW <- ihw(pvals, filters, alpha = alpha, adjustment_type = "bonferroni")
rejections(IHW)
c4D_res <- empOPW(pvalue = pvals, filter = filters, alpha = alpha, tail = 2,
delInterval = .01, max.group = 100,
effectType = "continuous", method = "BON")
C4D_res$rejections
c4D_res$rejections
c4D_res$opGroup
zscores <- filters
dbn_wgt <- bayes_weights(mu = zscores, sigma = rep(1, m), q = alpha/m)$w
sum(dbn_wgt)
m
rej_dbn <- sum(pvals <= alpha*dbn_wgt/m, na.rm = TRUE)
rej_dbn_bh <- sum(p.adjust(pvals/dbn_wgt, method = "BH") <= alpha, na.rm = TRUE)
rej_dbn
rej_dbn_bh
BON <- sum(pvals <= alpha/length(pvals))
BH <- sum(p.adjust(pvals, method = "BH") <= alpha)
BH
BON
