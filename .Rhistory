prob = probAll[1]
} else {
prob <- 1 - propTrueNull(p = pval_perGrp, method = "lfdr")
}
return(prob)
}
probVec <- sapply(1:group, fun_prob)
# smooting and nomalizing the ranks probability-------------
probVec_smooth <- smooth.spline(x = 1:group, y = probVec, df = df)$y
# if(any(probVec_smooth < 0)){
#     neg_val <- probVec_smooth[probVec_smooth < 0]
#     probVec_smooth <- probVec_smooth - neg_val + .000001
# }
probVec_smooth_norm <- probVec_smooth/sum(probVec_smooth, na.rm = TRUE)
return(probVec_smooth_norm)
}
results <- sapply(c(5,10,15), optimal_group_df, pvalue = OD$pvalue, filter = OD$filter,
h_breaks = 71, m = m, m1 = m1, alpha = .05,
mean_testEffect = 2.5, effectType = "continuous", method = "BH")
results
max.group=15
grp_seq <- seq(5, max.group, 5)
grp_seq
op_grp_df <- sapply(grp_seq, optimal_group_df, pvalue = OD$pvalue,
filter = OD$filter, h_breaks = h_breaks, m = m, m1 = m1,
alpha = alpha, mean_testEffect = mean_testEffect,
effectType = effectType, method = method)
op_grp_df
h_breaks
h_breaks = 51L
op_grp_df <- sapply(grp_seq, optimal_group_df, pvalue = OD$pvalue,
filter = OD$filter, h_breaks = h_breaks, m = m, m1 = m1,
alpha = alpha, mean_testEffect = mean_testEffect,
effectType = effectType, method = method)
op_grp_df
h_breaks = 71L
op_grp_df <- sapply(grp_seq, optimal_group_df, pvalue = OD$pvalue,
filter = OD$filter, h_breaks = h_breaks, m = m, m1 = m1,
alpha = alpha, mean_testEffect = mean_testEffect,
effectType = effectType, method = method)
op_grp_df
op_grp_df[3,]
.
which.max(op_grp_df[3,])
grp <- op_grp_df[1, which.max(op_grp_df[3,])]
grp
df <- op_grp_df[2, which.max(op_grp_df[3,])]
df
ranksProb <- prob_rank_givenEffect_emp(pvalue = pvalue, filter = filter,
group = grp, h_breaks = h_breaks, df = df,
effectType = effectType)
ranksProb
if(effectType == "continuous"){
wgt = weight_continuous(alpha = alpha, et = mean_testEffect, m = group,
ranksProb = ranksProb)
} else {
wgt = weight_binary(alpha = alpha, et = mean_testEffect, m = group,
m1 = m1/m*group, ranksProb = ranksProb)
}
if(!is.null(mean_testEffect)){
mean_testEffect <- mean_testEffect
} else {
# compute test statistics from the pvalues---------
test <- qnorm(pvalue/tail, lower.tail = FALSE)
test[which(!is.finite(test))] <- NA
# estimate the true alterantive test effect sizes----------------
if(m1 == 0){
test_effect_vec <- 0
} else {
test_effect_vec <-  sort(test, decreasing = TRUE)[1:m1]
}
# compute mean test effect----------
if(effectType == "continuous"){
mean_testEffect <- mean(test_effect_vec, na.rm = TRUE)
} else {
mean_testEffect <- median(test_effect_vec, na.rm = TRUE)
}
}
empOPW <- function(pvalue, filter, weight = NULL, ranksProb = NULL, mean_testEffect = NULL,
alpha = .05, tail = 1L, delInterval = .0001, max.group = 5L, h_breaks = 71L,
effectType = c("continuous", "binary"), method = c("BH", "BON"), ... )
{
# formulate a data set-------------
Data = tibble(pvalue, filter)
data_omit_na <- Data[which(!is.na(Data$pvalue)),]
OD <- data_omit_na[order(data_omit_na$filter, decreasing = TRUE), ]
OD_pvalue <- OD$pvalue
# compute the number of tests------------
m = length(OD_pvalue)
nullProp = qvalue(p = OD_pvalue, pi0.method = "bootstrap")$pi0
m0 = ceiling(nullProp*m)
m1 = m - m0
#check whether weight is provided------------
if(!is.null(weight)){
wgt <- weight
} else {
# estimate the mean test effect size-------------
if(!is.null(mean_testEffect)){
mean_testEffect <- mean_testEffect
} else {
# compute test statistics from the pvalues---------
test <- qnorm(pvalue/tail, lower.tail = FALSE)
test[which(!is.finite(test))] <- NA
# estimate the true alterantive test effect sizes----------------
if(m1 == 0){
test_effect_vec <- 0
} else {
test_effect_vec <-  sort(test, decreasing = TRUE)[1:m1]
}
# compute mean test effect----------
if(effectType == "continuous"){
mean_testEffect <- mean(test_effect_vec, na.rm = TRUE)
} else {
mean_testEffect <- median(test_effect_vec, na.rm = TRUE)
}
}
# find the optimal number of groups and degrees of freedom----------
grp_seq <- seq(5, max.group, 5)
op_grp_df <- sapply(grp_seq, optimal_group_df, pvalue = OD$pvalue,
filter = OD$filter, h_breaks = h_breaks, m = m, m1 = m1,
alpha = alpha, mean_testEffect = mean_testEffect,
effectType = effectType, method = method)
grp <- op_grp_df[1, which.max(op_grp_df[3,])]
df <- op_grp_df[2, which.max(op_grp_df[3,])]
message("computing ranks probabilities")
# compute the ranks probability of the tests given the mean effect
ranksProb <- prob_rank_givenEffect_emp(pvalue = pvalue, filter = filter,
group = grp, h_breaks = h_breaks, df = df,
effectType = effectType)
message("finished computing the ranks probabilities")
message("computing weights")
if(effectType == "continuous"){
wgt = weight_continuous(alpha = alpha, et = mean_testEffect,
m = group, ranksProb = ranksProb)
} else {
wgt = weight_binary(alpha = alpha, et = mean_testEffect, m = group,
m1 = m1/m*group, ranksProb = ranksProb)
}
message("finished computing the weights")
}
grpSize <- ceiling(m/grp)
wgt_all = rep(wgt, each = grpSize)[1:m]
message("comparing pvalues with thresholds")
if(method == "BH"){
padj <- p.adjust(OD_pvalue/wgt_all, method = "BH")
rejections_list = OD[which((padj <= alpha) == TRUE), ]
} else {
rejections_list = OD[which((OD_pvalue <= alpha*wgt_all/m) == TRUE), ]
}
# outputs--------------
n_rejections = dim(rejections_list)[1]
return(list(totalTests = length(pvalue), nullProp = nullProp,
ranksProb = ranksProb, weight = wgt_all,
rejections = n_rejections, rejections_list = rejections_list))
}
results3 <- empOPW(pvalue = pvals, filter = filters, ranksProb = probs,
effectType = "continuous", tail = 2, method = "BH")
results3
rm(list=ls())
prob_rank_givenEffect_emp <- function(pvalue, filter, group = 5L, h_breaks = 71L,
df = 3, effectType = c("continuous", "binary"))
{
Data = tibble(pvalue, filter)
data_omit_na <- Data[which(!is.na(Data$pvalue)),]
OD <- data_omit_na[order(data_omit_na$filter, decreasing = TRUE), ]
OD_pvalue <- OD$pvalue
grpSize <- ceiling(length(OD_pvalue)/group)
# function to compute ranks probbaility per group--------------
fun_prob <- function(grp)
{
pval_perGrp <- OD_pvalue[(grp*grpSize - grpSize + 1):(grp*grpSize)]
if(effectType == "continuous"){
hist_dens <- hist(pval_perGrp, freq = FALSE,
breaks = seq(0, 1, length = h_breaks))$density
probAll = hist_dens/sum(hist_dens)
prob = probAll[1]
} else {
prob <- 1 - propTrueNull(p = pval_perGrp, method = "lfdr")
}
return(prob)
}
probVec <- sapply(1:group, fun_prob)
# smooting and nomalizing the ranks probability-------------
probVec_smooth <- smooth.spline(x = 1:group, y = probVec, df = df)$y
# if(any(probVec_smooth < 0)){
#     neg_val <- probVec_smooth[probVec_smooth < 0]
#     probVec_smooth <- probVec_smooth - neg_val + .000001
# }
probVec_smooth_norm <- probVec_smooth/sum(probVec_smooth, na.rm = TRUE)
return(probVec_smooth_norm)
}
X = runif(100000, min = 0, max = 2.5)         # covariate
H = rbinom(length(X), size = 1, prob = 0.1)   # hypothesis true or false
Z = rnorm(length(X), mean = H * X)            # Z-score
p = 1 - pnorm(Z)
# apply the function to compute the rank proabbility
grp = 10
ranksProb = prob_rank_givenEffect_emp(pvalue = p, filter = X, group = grp,
h_breaks = 101, effectType = "continuous")
plot(1:grp, ranksProb, type="l", xlab = "ranks", ylab = "P(rank | effect)")
ranksProb = prob_rank_givenEffect_emp(pvalue = p, filter = X, group = grp,
h_breaks = 101, effectType = "binary")
library(limma)
ranksProb = prob_rank_givenEffect_emp(pvalue = p, filter = X, group = grp,
h_breaks = 101, effectType = "binary")
plot(1:grp, ranksProb, type="l", xlab = "ranks", ylab = "P(rank | effect)")
rm(list=ls())
optimal_group_df <- function(group = 5L, pvalue, filter, h_breaks = 71L, m, m1,
alpha = .05, mean_testEffect, effectType = c("continuous", "binary"),
method = c("BH", "BON"))
{
optimal_df <- function(df)
{
# ranks probability--------------
ranksProb <- prob_rank_givenEffect_emp(pvalue = pvalue, filter = filter,
group = group, h_breaks = h_breaks, df = df,
effectType = effectType)
# weights-----------
if(effectType == "continuous"){
wgt = weight_continuous(alpha = alpha, et = mean_testEffect,
m = group, ranksProb = ranksProb)
} else {
wgt = weight_binary(alpha = alpha, et = mean_testEffect, m = group,
m1 = m1/m*group, ranksProb = ranksProb)
}
# weight for all test----------
grpSize <- ceiling(m/group)
wgt_all = rep(wgt, each = grpSize)[1:m]
# count number of rejections-----------
if(method == "BH"){
padj <- p.adjust(pvalue/wgt_all, method = method)
n_rejections = sum(padj <= alpha, na.rm = TRUE)
} else {
n_rejections = sum(pvalue <= alpha*wgt_all/m, na.rm = TRUE)
}
return(c(df = df, n_rej = n_rejections))
}
message(paste("computing for group", group))
# not necessary to use all df
df_and_rej <- sapply(seq(2, group, 3), optimal_df)
op_df_rej <- df_and_rej[ , which.max(df_and_rej[2,])]
return(c(group = group, op_df_rej))
}
m = 10000
set.seed(3)
filters = runif(m, min = 0, max = 2.5)          # filter statistics
H = rbinom(m, size = 1, prob = 0.1)             # hypothesis true or false
tests = rnorm(m, mean = H * filters)            # Z-score
pvals = 1 - pnorm(tests)                        # pvalue
results <- optimal_group_df(group = 5, pvalue = pvals, filter = filters,
h_breaks = 71, m = m, m1 = 8000, alpha = .05,
mean_testEffect = 2.5, effectType = "continuous", method = "BH")
results
results <- optimal_group_df(group = 10, pvalue = pvals, filter = filters,
h_breaks = 71, m = m, m1 = 8000, alpha = .05,
mean_testEffect = 2.5, effectType = "continuous", method = "BH")
results
rm(list=ls())
empOPW <- function(pvalue, filter, weight = NULL, ranksProb = NULL, mean_testEffect = NULL,
alpha = .05, tail = 1L, delInterval = .0001, max.group = 5L, h_breaks = 71L,
effectType = c("continuous", "binary"), method = c("BH", "BON"), ... )
{
# formulate a data set-------------
Data = tibble(pvalue, filter)
data_omit_na <- Data[which(!is.na(Data$pvalue)),]
OD <- data_omit_na[order(data_omit_na$filter, decreasing = TRUE), ]
OD_pvalue <- OD$pvalue
# compute the number of tests------------
m = length(OD_pvalue)
nullProp = qvalue(p = OD_pvalue, pi0.method = "bootstrap")$pi0
m0 = ceiling(nullProp*m)
m1 = m - m0
#check whether weight is provided------------
if(!is.null(weight)){
wgt <- weight
} else {
# estimate the mean test effect size-------------
if(!is.null(mean_testEffect)){
mean_testEffect <- mean_testEffect
} else {
# compute test statistics from the pvalues---------
test <- qnorm(pvalue/tail, lower.tail = FALSE)
test[which(!is.finite(test))] <- NA
# estimate the true alterantive test effect sizes----------------
if(m1 == 0){
test_effect_vec <- 0
} else {
test_effect_vec <-  sort(test, decreasing = TRUE)[1:m1]
}
# compute mean test effect----------
if(effectType == "continuous"){
mean_testEffect <- mean(test_effect_vec, na.rm = TRUE)
} else {
mean_testEffect <- median(test_effect_vec, na.rm = TRUE)
}
}
# find the optimal number of groups and degrees of freedom----------
grp_seq <- seq(5, max.group, 5)
op_grp_df <- sapply(grp_seq, optimal_group_df, pvalue = OD$pvalue,
filter = OD$filter, h_breaks = h_breaks, m = m, m1 = m1,
alpha = alpha, mean_testEffect = mean_testEffect,
effectType = effectType, method = method)
grp <- op_grp_df[1, which.max(op_grp_df[3,])]
df <- op_grp_df[2, which.max(op_grp_df[3,])]
message("computing ranks probabilities")
# compute the ranks probability of the tests given the mean effect
ranksProb <- prob_rank_givenEffect_emp(pvalue = pvalue, filter = filter,
group = grp, h_breaks = h_breaks, df = df,
effectType = effectType)
message("finished computing the ranks probabilities")
message("computing weights")
if(effectType == "continuous"){
wgt = weight_continuous(alpha = alpha, et = mean_testEffect,
m = group, ranksProb = ranksProb)
} else {
wgt = weight_binary(alpha = alpha, et = mean_testEffect, m = group,
m1 = m1/m*group, ranksProb = ranksProb)
}
message("finished computing the weights")
}
grpSize <- ceiling(m/grp)
wgt_all = rep(wgt, each = grpSize)[1:m]
message("comparing pvalues with thresholds")
if(method == "BH"){
padj <- p.adjust(OD_pvalue/wgt_all, method = "BH")
rejections_list = OD[which((padj <= alpha) == TRUE), ]
} else {
rejections_list = OD[which((OD_pvalue <= alpha*wgt_all/m) == TRUE), ]
}
# outputs--------------
n_rejections = dim(rejections_list)[1]
return(list(totalTests = length(pvalue), nullProp = nullProp,
ranksProb = ranksProb, weight = wgt_all,
rejections = n_rejections, rejections_list = rejections_list))
}
m = 10000
set.seed(3)
filters = runif(m, min = 0, max = 2.5)          # filter statistics
H = rbinom(m, size = 1, prob = 0.1)             # hypothesis true or false
tests = rnorm(m, mean = H * filters)            # Z-score
pvals = 1 - pnorm(tests)                        # pvalue
# general use
results <- empOPW(pvalue = pvals, filter = filters, effectType = "continuous",
method = "BH")
empOPW <- function(pvalue, filter, weight = NULL, ranksProb = NULL, mean_testEffect = NULL,
alpha = .05, tail = 1L, delInterval = .0001, max.group = 5L, h_breaks = 71L,
effectType = c("continuous", "binary"), method = c("BH", "BON"), ... )
{
# formulate a data set-------------
Data = tibble(pvalue, filter)
data_omit_na <- Data[which(!is.na(Data$pvalue)),]
OD <- data_omit_na[order(data_omit_na$filter, decreasing = TRUE), ]
OD_pvalue <- OD$pvalue
# compute the number of tests------------
m = length(OD_pvalue)
nullProp = qvalue(p = OD_pvalue, pi0.method = "bootstrap")$pi0
m0 = ceiling(nullProp*m)
m1 = m - m0
#check whether weight is provided------------
if(!is.null(weight)){
wgt <- weight
} else {
# estimate the mean test effect size-------------
if(!is.null(mean_testEffect)){
mean_testEffect <- mean_testEffect
} else {
# compute test statistics from the pvalues---------
test <- qnorm(pvalue/tail, lower.tail = FALSE)
test[which(!is.finite(test))] <- NA
# estimate the true alterantive test effect sizes----------------
if(m1 == 0){
test_effect_vec <- 0
} else {
test_effect_vec <-  sort(test, decreasing = TRUE)[1:m1]
}
# compute mean test effect----------
if(effectType == "continuous"){
mean_testEffect <- mean(test_effect_vec, na.rm = TRUE)
} else {
mean_testEffect <- median(test_effect_vec, na.rm = TRUE)
}
}
# find the optimal number of groups and degrees of freedom----------
grp_seq <- seq(5, max.group, 5)
op_grp_df <- sapply(grp_seq, optimal_group_df, pvalue = OD$pvalue,
filter = OD$filter, h_breaks = h_breaks, m = m, m1 = m1,
alpha = alpha, mean_testEffect = mean_testEffect,
effectType = effectType, method = method)
grp <- op_grp_df[1, which.max(op_grp_df[3,])]
df <- op_grp_df[2, which.max(op_grp_df[3,])]
message("computing ranks probabilities")
# compute the ranks probability of the tests given the mean effect
ranksProb <- prob_rank_givenEffect_emp(pvalue = pvalue, filter = filter,
group = grp, h_breaks = h_breaks, df = df,
effectType = effectType)
message("finished computing the ranks probabilities")
message("computing weights")
if(effectType == "continuous"){
wgt = weight_continuous(alpha = alpha, et = mean_testEffect,
m = grp, ranksProb = ranksProb)
} else {
wgt = weight_binary(alpha = alpha, et = mean_testEffect, m = group,
m1 = m1/m*grp, ranksProb = ranksProb)
}
message("finished computing the weights")
}
grpSize <- ceiling(m/grp)
wgt_all = rep(wgt, each = grpSize)[1:m]
message("comparing pvalues with thresholds")
if(method == "BH"){
padj <- p.adjust(OD_pvalue/wgt_all, method = "BH")
rejections_list = OD[which((padj <= alpha) == TRUE), ]
} else {
rejections_list = OD[which((OD_pvalue <= alpha*wgt_all/m) == TRUE), ]
}
# outputs--------------
n_rejections = dim(rejections_list)[1]
return(list(totalTests = length(pvalue), nullProp = nullProp,
ranksProb = ranksProb, weight = wgt_all,
rejections = n_rejections, rejections_list = rejections_list))
}
results2 <- empOPW(pvalue = pvals, filter = filters, mean_testEffect = et,
tail = 2, effectType = "continuous", method = "BH")
results <- empOPW(pvalue = pvals, filter = filters, effectType = "continuous",
method = "BH")
results
library(qvalue)
nullProp = qvalue(p = pvals, pi0.method = "bootstrap")$pi0
m0 = ceiling(nullProp*m)
m1 = m - m0
et = mean(sort(tests, decreasing = TRUE)[1:m1])
results2 <- empOPW(pvalue = pvals, filter = filters, mean_testEffect = et,
tail = 2, effectType = "continuous", method = "BH")
results2
grp = 5
probs = prob_rank_givenEffect_emp(pvalue = pvals, filter = filters, group = grp,
h_breaks = 101, effectType = "continuous")
results3 <- empOPW(pvalue = pvals, filter = filters, ranksProb = probs,
effectType = "continuous", tail = 2, method = "BH")
results3
wgt <- weight_continuous(alpha = .05, et = et, m = grp, ranksProb = probs)
results4 <- empOPW(pvalue = pvals, filter = filters, weight = wgt,
effectType = "continuous", alpha = .05, method = "BH")
results4
library(testthat)
install.packages("testthat")
install.packages("testthat")
library(testthat)
library(empOPW)
bottomly_count_table <- read.table("bottomly_count_table.txt",h=T)
bottomly_phenodata <- read.table("bottomly_phenodata.txt",h=T)
countData <- as.matrix(bottomly_count_table[,-1])		# counts
condition <- factor(bottomly_phenodata[,3])				# strain as factor
dds <- DESeqDataSetFromMatrix(countData, DataFrame(condition), ~ condition)
dds <- DESeq(dds)
bottomly <- results(dds)
colnames(bottomly)
pvals = bottomly$pvalue
filters = bottomly$baseMean
alphaVec <- seq(.05, .1, length = 5)
rej <- NULL
for(alpha in alphaVec){
bot_res <- empOPW(pvalue = pvals, filter = filters, alpha = alpha, tail = 2,
max.group = 15, effectType = "continuous", method = "BH")
rej <- c(rej, bot_res$rejections)
}
rej
library(devtools)
install_github("mshasan/empOPW")
library(MASS)
library(qvalue)
library(limma)
library(splines)
library(OPWeight)
library(OPWpaper)
library(empOPW)
library(DESeq2)
dds <- DESeqDataSetFromMatrix(countData, DataFrame(condition), ~ condition)
dds <- DESeq(dds)
bottomly <- results(dds)
colnames(bottomly)
pvals = bottomly$pvalue
filters = bottomly$baseMean
alphaVec <- seq(.05, .1, length = 5)
rej <- NULL
for(alpha in alphaVec){
bot_res <- empOPW(pvalue = pvals, filter = filters, alpha = alpha, tail = 2,
max.group = 15, effectType = "continuous", method = "BH")
rej <- c(rej, bot_res$rejections)
}
rej
setwd("U:/Documents/My Research (UGA)/Multiple Hypoetheses/Article-1")
load("U:/Documents/My Research (UGA)/Multiple Hypoetheses/Article-1/proteomics_data_example.RDATA")
rej_mat_prot_FDR
proteomics_file <- system.file("extdata/real_data","science_signaling.csv",
package = "IHWpaper")
proteomics_df <- read.csv(proteomics_file, stringsAsFactors = F)
proteomics_df$pvalue <- rank(proteomics_df$p1, ties.method="first")*proteomics_df$p1/nrow(proteomics_df)
proteomics_df$test = qnorm(proteomics_df$pvalue, lower.tail = F)
names(proteomics_df)
pvals = proteomics_df$pvalue
filters = proteomics_df$X..peptides
pvals = proteomics_df$pvalue
filters = proteomics_df$X..peptides
alphaVec <- seq(.05, .1, length = 5)
rej_prot <- NULL
for(alpha in alphaVec){
prot_res <- empOPW(pvalue = pvals, filter = filters, alpha = alpha, tail = 1,
max.group = 5, effectType = "continuous", method = "BH")
rej_prot  <- c(rej_prot , prot_res$rejections)
}
rej_prot
